{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of XAI on CNN model trained on the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the mnist data and setting up the test and train data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5c4c74db70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_batch_size = 128\n",
    "test_bach_size = 1000\n",
    "random_seed = 1234\n",
    "\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.ToTensor(), torchvision.transforms.Normalize( (0.1307,), (0.3081,))]\n",
    "    )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST(\n",
    "    \"./data/\",train= True, download=True, transform= image_transform\n",
    "),batch_size= train_batch_size, shuffle= True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST(\n",
    "    \"./data/\",train= False, download=True, transform=image_transform\n",
    "),batch_size= test_bach_size, shuffle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Classifier(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(MNIST_Classifier,self).__init__()\n",
    "        self.conv_layer_1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv_layer_2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.linear_1 = nn.Linear(320,50)\n",
    "        self.linear_2 = nn.Linear(50,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv_layer_1(x),2))\n",
    "        x = F.relu(F.max_pool2d(self.dropout(self.conv_layer_2(x)),2))\n",
    "        # reshaping to fit linear shape\n",
    "        x = x.view(-1,320)\n",
    "        x = F.relu(self.linear_1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = MNIST_Classifier()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(network,test_loader):\n",
    "    network.eval()\n",
    "    test_loss_total = 0\n",
    "    no_of_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                network.cuda()\n",
    "                data = data.cuda()\n",
    "                target = target.cuda()\n",
    "            output = network(data)\n",
    "            test_loss_total += F.nll_loss(output, target, reduction='sum').item()\n",
    "            prediction = output.data.max(1, keepdim=True)[1]\n",
    "            no_of_correct += prediction.eq(target.data.view_as(prediction)).sum()\n",
    "        test_loss_total /= len(test_loader.dataset)\n",
    "        print(\"Test: avg loss: {:.6f} accuracy {}/{} percentage {:.1f}\".format(test_loss_total,\n",
    "        no_of_correct,len(test_loader.dataset),  100 * (no_of_correct/len(test_loader.dataset))))\n",
    "\n",
    "    return test_loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,interval,network,optimizer,data_loader,test_loader=test_loader):\n",
    "    # Setting the network to training mode\n",
    "    training_loss_current_min = 0 \n",
    "    for batch_no, (data, target) in enumerate(data_loader):\n",
    "        network.train()\n",
    "        optimizer.zero_grad()\n",
    "        # Moving the elements to the gpu\n",
    "        if torch.cuda.is_available():\n",
    "            network.cuda()\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # setting the loss in the first iteration\n",
    "        if batch_no % interval == 0:\n",
    "            print('Training: {} : {:.1f} : Loss :{:.6f}'.format(epoch,\n",
    "            100. * batch_no / len(data_loader), loss.item()))\n",
    "            test_loss = test(network=network,test_loader=test_loader)\n",
    "            if training_loss_current_min == 0:\n",
    "                training_loss_current_min = test_loss\n",
    "            if training_loss_current_min > test_loss:\n",
    "                print('The current min {:.6f} new min {:.6f} saving...'.format(training_loss_current_min,test_loss))\n",
    "                torch.save(network.state_dict(),\"./result/model.pth\")\n",
    "                training_loss_current_min = test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: avg loss: 2.309193 accuracy 1034/10000 percentage 10.3\n",
      "Training: 1 : 0.0 : Loss :2.297200\n",
      "Test: avg loss: 2.308351 accuracy 1036/10000 percentage 10.4\n",
      "Training: 1 : 2.1 : Loss :2.318082\n",
      "Test: avg loss: 2.295337 accuracy 1234/10000 percentage 12.3\n",
      "The current min 2.308351 new min 2.295337 saving...\n",
      "Training: 1 : 4.3 : Loss :2.308035\n",
      "Test: avg loss: 2.283520 accuracy 1706/10000 percentage 17.1\n",
      "The current min 2.295337 new min 2.283520 saving...\n",
      "Training: 1 : 6.4 : Loss :2.270305\n",
      "Test: avg loss: 2.272605 accuracy 1870/10000 percentage 18.7\n",
      "The current min 2.283520 new min 2.272605 saving...\n",
      "Training: 1 : 8.5 : Loss :2.258447\n",
      "Test: avg loss: 2.259065 accuracy 2032/10000 percentage 20.3\n",
      "The current min 2.272605 new min 2.259065 saving...\n",
      "Training: 1 : 10.7 : Loss :2.251665\n",
      "Test: avg loss: 2.242946 accuracy 2340/10000 percentage 23.4\n",
      "The current min 2.259065 new min 2.242946 saving...\n",
      "Training: 1 : 12.8 : Loss :2.229795\n",
      "Test: avg loss: 2.222235 accuracy 3272/10000 percentage 32.7\n",
      "The current min 2.242946 new min 2.222235 saving...\n",
      "Training: 1 : 14.9 : Loss :2.217756\n",
      "Test: avg loss: 2.198093 accuracy 4459/10000 percentage 44.6\n",
      "The current min 2.222235 new min 2.198093 saving...\n",
      "Training: 1 : 17.1 : Loss :2.218215\n",
      "Test: avg loss: 2.167383 accuracy 5229/10000 percentage 52.3\n",
      "The current min 2.198093 new min 2.167383 saving...\n",
      "Training: 1 : 19.2 : Loss :2.146918\n",
      "Test: avg loss: 2.120610 accuracy 5486/10000 percentage 54.9\n",
      "The current min 2.167383 new min 2.120610 saving...\n",
      "Training: 1 : 21.3 : Loss :2.128527\n",
      "Test: avg loss: 2.069226 accuracy 6048/10000 percentage 60.5\n",
      "The current min 2.120610 new min 2.069226 saving...\n",
      "Training: 1 : 23.5 : Loss :2.050356\n",
      "Test: avg loss: 1.984448 accuracy 7042/10000 percentage 70.4\n",
      "The current min 2.069226 new min 1.984448 saving...\n",
      "Training: 1 : 25.6 : Loss :1.983872\n",
      "Test: avg loss: 1.868443 accuracy 7175/10000 percentage 71.8\n",
      "The current min 1.984448 new min 1.868443 saving...\n",
      "Training: 1 : 27.7 : Loss :1.986581\n",
      "Test: avg loss: 1.733593 accuracy 7482/10000 percentage 74.8\n",
      "The current min 1.868443 new min 1.733593 saving...\n",
      "Training: 1 : 29.9 : Loss :1.886984\n",
      "Test: avg loss: 1.567863 accuracy 7784/10000 percentage 77.8\n",
      "The current min 1.733593 new min 1.567863 saving...\n",
      "Training: 1 : 32.0 : Loss :1.661379\n",
      "Test: avg loss: 1.393855 accuracy 8112/10000 percentage 81.1\n",
      "The current min 1.567863 new min 1.393855 saving...\n",
      "Training: 1 : 34.1 : Loss :1.539332\n",
      "Test: avg loss: 1.249943 accuracy 7937/10000 percentage 79.4\n",
      "The current min 1.393855 new min 1.249943 saving...\n",
      "Training: 1 : 36.2 : Loss :1.494285\n",
      "Test: avg loss: 1.118960 accuracy 8060/10000 percentage 80.6\n",
      "The current min 1.249943 new min 1.118960 saving...\n",
      "Training: 1 : 38.4 : Loss :1.306326\n",
      "Test: avg loss: 0.995838 accuracy 8174/10000 percentage 81.7\n",
      "The current min 1.118960 new min 0.995838 saving...\n",
      "Training: 1 : 40.5 : Loss :1.170654\n",
      "Test: avg loss: 0.894625 accuracy 8333/10000 percentage 83.3\n",
      "The current min 0.995838 new min 0.894625 saving...\n",
      "Training: 1 : 42.6 : Loss :1.204527\n",
      "Test: avg loss: 0.820863 accuracy 8483/10000 percentage 84.8\n",
      "The current min 0.894625 new min 0.820863 saving...\n",
      "Training: 1 : 44.8 : Loss :1.159295\n",
      "Test: avg loss: 0.754536 accuracy 8507/10000 percentage 85.1\n",
      "The current min 0.820863 new min 0.754536 saving...\n",
      "Training: 1 : 46.9 : Loss :1.028854\n",
      "Test: avg loss: 0.688750 accuracy 8620/10000 percentage 86.2\n",
      "The current min 0.754536 new min 0.688750 saving...\n",
      "Training: 1 : 49.0 : Loss :1.110966\n",
      "Test: avg loss: 0.654900 accuracy 8659/10000 percentage 86.6\n",
      "The current min 0.688750 new min 0.654900 saving...\n",
      "Training: 1 : 51.2 : Loss :0.947927\n",
      "Test: avg loss: 0.608297 accuracy 8729/10000 percentage 87.3\n",
      "The current min 0.654900 new min 0.608297 saving...\n",
      "Training: 1 : 53.3 : Loss :0.865620\n",
      "Test: avg loss: 0.585765 accuracy 8684/10000 percentage 86.8\n",
      "The current min 0.608297 new min 0.585765 saving...\n",
      "Training: 1 : 55.4 : Loss :0.824077\n",
      "Test: avg loss: 0.538084 accuracy 8789/10000 percentage 87.9\n",
      "The current min 0.585765 new min 0.538084 saving...\n",
      "Training: 1 : 57.6 : Loss :1.018419\n",
      "Test: avg loss: 0.524523 accuracy 8703/10000 percentage 87.0\n",
      "The current min 0.538084 new min 0.524523 saving...\n",
      "Training: 1 : 59.7 : Loss :0.785282\n",
      "Test: avg loss: 0.489148 accuracy 8834/10000 percentage 88.3\n",
      "The current min 0.524523 new min 0.489148 saving...\n",
      "Training: 1 : 61.8 : Loss :0.825866\n",
      "Test: avg loss: 0.482554 accuracy 8832/10000 percentage 88.3\n",
      "The current min 0.489148 new min 0.482554 saving...\n",
      "Training: 1 : 64.0 : Loss :0.827847\n",
      "Test: avg loss: 0.465304 accuracy 8855/10000 percentage 88.5\n",
      "The current min 0.482554 new min 0.465304 saving...\n",
      "Training: 1 : 66.1 : Loss :0.744539\n",
      "Test: avg loss: 0.448387 accuracy 8926/10000 percentage 89.3\n",
      "The current min 0.465304 new min 0.448387 saving...\n",
      "Training: 1 : 68.2 : Loss :0.713816\n",
      "Test: avg loss: 0.435419 accuracy 8930/10000 percentage 89.3\n",
      "The current min 0.448387 new min 0.435419 saving...\n",
      "Training: 1 : 70.4 : Loss :1.018289\n",
      "Test: avg loss: 0.425494 accuracy 8952/10000 percentage 89.5\n",
      "The current min 0.435419 new min 0.425494 saving...\n",
      "Training: 1 : 72.5 : Loss :0.733156\n",
      "Test: avg loss: 0.405324 accuracy 8974/10000 percentage 89.7\n",
      "The current min 0.425494 new min 0.405324 saving...\n",
      "Training: 1 : 74.6 : Loss :0.745000\n",
      "Test: avg loss: 0.400560 accuracy 8980/10000 percentage 89.8\n",
      "The current min 0.405324 new min 0.400560 saving...\n",
      "Training: 1 : 76.8 : Loss :0.712807\n",
      "Test: avg loss: 0.408341 accuracy 8914/10000 percentage 89.1\n",
      "Training: 1 : 78.9 : Loss :0.720774\n",
      "Test: avg loss: 0.387226 accuracy 9006/10000 percentage 90.1\n",
      "The current min 0.400560 new min 0.387226 saving...\n",
      "Training: 1 : 81.0 : Loss :0.666701\n",
      "Test: avg loss: 0.385904 accuracy 8980/10000 percentage 89.8\n",
      "The current min 0.387226 new min 0.385904 saving...\n",
      "Training: 1 : 83.2 : Loss :0.757134\n",
      "Test: avg loss: 0.361675 accuracy 9035/10000 percentage 90.3\n",
      "The current min 0.385904 new min 0.361675 saving...\n",
      "Training: 1 : 85.3 : Loss :0.925366\n",
      "Test: avg loss: 0.363015 accuracy 9050/10000 percentage 90.5\n",
      "Training: 1 : 87.4 : Loss :0.608243\n",
      "Test: avg loss: 0.350919 accuracy 9044/10000 percentage 90.4\n",
      "The current min 0.361675 new min 0.350919 saving...\n",
      "Training: 1 : 89.6 : Loss :0.746165\n",
      "Test: avg loss: 0.345071 accuracy 9074/10000 percentage 90.7\n",
      "The current min 0.350919 new min 0.345071 saving...\n",
      "Training: 1 : 91.7 : Loss :0.768083\n",
      "Test: avg loss: 0.347914 accuracy 9074/10000 percentage 90.7\n",
      "Training: 1 : 93.8 : Loss :0.639787\n",
      "Test: avg loss: 0.339134 accuracy 9060/10000 percentage 90.6\n",
      "The current min 0.345071 new min 0.339134 saving...\n",
      "Training: 1 : 95.9 : Loss :0.645073\n",
      "Test: avg loss: 0.333487 accuracy 9084/10000 percentage 90.8\n",
      "The current min 0.339134 new min 0.333487 saving...\n",
      "Training: 1 : 98.1 : Loss :0.567389\n",
      "Test: avg loss: 0.330945 accuracy 9103/10000 percentage 91.0\n",
      "The current min 0.333487 new min 0.330945 saving...\n",
      "Training: 2 : 0.0 : Loss :0.699030\n",
      "Test: avg loss: 0.326618 accuracy 9092/10000 percentage 90.9\n",
      "Training: 2 : 2.1 : Loss :0.496365\n",
      "Test: avg loss: 0.331202 accuracy 9066/10000 percentage 90.7\n",
      "Training: 2 : 4.3 : Loss :0.643887\n",
      "Test: avg loss: 0.311775 accuracy 9130/10000 percentage 91.3\n",
      "The current min 0.326618 new min 0.311775 saving...\n",
      "Training: 2 : 6.4 : Loss :0.496054\n",
      "Test: avg loss: 0.308540 accuracy 9166/10000 percentage 91.7\n",
      "The current min 0.311775 new min 0.308540 saving...\n",
      "Training: 2 : 8.5 : Loss :0.629084\n",
      "Test: avg loss: 0.304024 accuracy 9158/10000 percentage 91.6\n",
      "The current min 0.308540 new min 0.304024 saving...\n",
      "Training: 2 : 10.7 : Loss :0.490257\n",
      "Test: avg loss: 0.305546 accuracy 9153/10000 percentage 91.5\n",
      "Training: 2 : 12.8 : Loss :0.589420\n",
      "Test: avg loss: 0.297222 accuracy 9129/10000 percentage 91.3\n",
      "The current min 0.304024 new min 0.297222 saving...\n",
      "Training: 2 : 14.9 : Loss :0.384279\n",
      "Test: avg loss: 0.292789 accuracy 9153/10000 percentage 91.5\n",
      "The current min 0.297222 new min 0.292789 saving...\n",
      "Training: 2 : 17.1 : Loss :0.587468\n",
      "Test: avg loss: 0.289046 accuracy 9141/10000 percentage 91.4\n",
      "The current min 0.292789 new min 0.289046 saving...\n",
      "Training: 2 : 19.2 : Loss :0.670216\n",
      "Test: avg loss: 0.289336 accuracy 9187/10000 percentage 91.9\n",
      "Training: 2 : 21.3 : Loss :0.589248\n",
      "Test: avg loss: 0.290262 accuracy 9167/10000 percentage 91.7\n",
      "Training: 2 : 23.5 : Loss :0.570320\n",
      "Test: avg loss: 0.279456 accuracy 9180/10000 percentage 91.8\n",
      "The current min 0.289046 new min 0.279456 saving...\n",
      "Training: 2 : 25.6 : Loss :0.423700\n",
      "Test: avg loss: 0.279112 accuracy 9208/10000 percentage 92.1\n",
      "The current min 0.279456 new min 0.279112 saving...\n",
      "Training: 2 : 27.7 : Loss :0.553852\n",
      "Test: avg loss: 0.278324 accuracy 9207/10000 percentage 92.1\n",
      "The current min 0.279112 new min 0.278324 saving...\n",
      "Training: 2 : 29.9 : Loss :0.581779\n",
      "Test: avg loss: 0.271793 accuracy 9201/10000 percentage 92.0\n",
      "The current min 0.278324 new min 0.271793 saving...\n",
      "Training: 2 : 32.0 : Loss :0.547685\n",
      "Test: avg loss: 0.265640 accuracy 9222/10000 percentage 92.2\n",
      "The current min 0.271793 new min 0.265640 saving...\n",
      "Training: 2 : 34.1 : Loss :0.684078\n",
      "Test: avg loss: 0.274283 accuracy 9239/10000 percentage 92.4\n",
      "Training: 2 : 36.2 : Loss :0.666211\n",
      "Test: avg loss: 0.264099 accuracy 9250/10000 percentage 92.5\n",
      "The current min 0.265640 new min 0.264099 saving...\n",
      "Training: 2 : 38.4 : Loss :0.563730\n",
      "Test: avg loss: 0.262452 accuracy 9229/10000 percentage 92.3\n",
      "The current min 0.264099 new min 0.262452 saving...\n",
      "Training: 2 : 40.5 : Loss :0.595783\n",
      "Test: avg loss: 0.256451 accuracy 9253/10000 percentage 92.5\n",
      "The current min 0.262452 new min 0.256451 saving...\n",
      "Training: 2 : 42.6 : Loss :0.586718\n",
      "Test: avg loss: 0.253369 accuracy 9258/10000 percentage 92.6\n",
      "The current min 0.256451 new min 0.253369 saving...\n",
      "Training: 2 : 44.8 : Loss :0.569396\n",
      "Test: avg loss: 0.256525 accuracy 9240/10000 percentage 92.4\n",
      "Training: 2 : 46.9 : Loss :0.450479\n",
      "Test: avg loss: 0.248264 accuracy 9252/10000 percentage 92.5\n",
      "The current min 0.253369 new min 0.248264 saving...\n",
      "Training: 2 : 49.0 : Loss :0.424940\n",
      "Test: avg loss: 0.249432 accuracy 9249/10000 percentage 92.5\n",
      "Training: 2 : 51.2 : Loss :0.555050\n",
      "Test: avg loss: 0.242241 accuracy 9288/10000 percentage 92.9\n",
      "The current min 0.248264 new min 0.242241 saving...\n",
      "Training: 2 : 53.3 : Loss :0.556970\n",
      "Test: avg loss: 0.235972 accuracy 9322/10000 percentage 93.2\n",
      "The current min 0.242241 new min 0.235972 saving...\n",
      "Training: 2 : 55.4 : Loss :0.555162\n",
      "Test: avg loss: 0.239518 accuracy 9276/10000 percentage 92.8\n",
      "Training: 2 : 57.6 : Loss :0.590536\n",
      "Test: avg loss: 0.241383 accuracy 9313/10000 percentage 93.1\n",
      "Training: 2 : 59.7 : Loss :0.407708\n",
      "Test: avg loss: 0.236597 accuracy 9303/10000 percentage 93.0\n",
      "Training: 2 : 61.8 : Loss :0.725465\n",
      "Test: avg loss: 0.241837 accuracy 9287/10000 percentage 92.9\n",
      "Training: 2 : 64.0 : Loss :0.477948\n",
      "Test: avg loss: 0.231321 accuracy 9306/10000 percentage 93.1\n",
      "The current min 0.235972 new min 0.231321 saving...\n",
      "Training: 2 : 66.1 : Loss :0.499733\n",
      "Test: avg loss: 0.232532 accuracy 9298/10000 percentage 93.0\n",
      "Training: 2 : 68.2 : Loss :0.482252\n",
      "Test: avg loss: 0.235292 accuracy 9271/10000 percentage 92.7\n",
      "Training: 2 : 70.4 : Loss :0.408018\n",
      "Test: avg loss: 0.230926 accuracy 9300/10000 percentage 93.0\n",
      "The current min 0.231321 new min 0.230926 saving...\n",
      "Training: 2 : 72.5 : Loss :0.364386\n",
      "Test: avg loss: 0.221381 accuracy 9334/10000 percentage 93.3\n",
      "The current min 0.230926 new min 0.221381 saving...\n",
      "Training: 2 : 74.6 : Loss :0.503734\n",
      "Test: avg loss: 0.224519 accuracy 9328/10000 percentage 93.3\n",
      "Training: 2 : 76.8 : Loss :0.553892\n",
      "Test: avg loss: 0.217913 accuracy 9366/10000 percentage 93.7\n",
      "The current min 0.221381 new min 0.217913 saving...\n",
      "Training: 2 : 78.9 : Loss :0.574814\n",
      "Test: avg loss: 0.217406 accuracy 9342/10000 percentage 93.4\n",
      "The current min 0.217913 new min 0.217406 saving...\n",
      "Training: 2 : 81.0 : Loss :0.428804\n",
      "Test: avg loss: 0.216591 accuracy 9338/10000 percentage 93.4\n",
      "The current min 0.217406 new min 0.216591 saving...\n",
      "Training: 2 : 83.2 : Loss :0.423940\n",
      "Test: avg loss: 0.213173 accuracy 9370/10000 percentage 93.7\n",
      "The current min 0.216591 new min 0.213173 saving...\n",
      "Training: 2 : 85.3 : Loss :0.429005\n",
      "Test: avg loss: 0.211564 accuracy 9343/10000 percentage 93.4\n",
      "The current min 0.213173 new min 0.211564 saving...\n",
      "Training: 2 : 87.4 : Loss :0.596479\n",
      "Test: avg loss: 0.215702 accuracy 9338/10000 percentage 93.4\n",
      "Training: 2 : 89.6 : Loss :0.454024\n",
      "Test: avg loss: 0.208682 accuracy 9372/10000 percentage 93.7\n",
      "The current min 0.211564 new min 0.208682 saving...\n",
      "Training: 2 : 91.7 : Loss :0.386690\n",
      "Test: avg loss: 0.209688 accuracy 9369/10000 percentage 93.7\n",
      "Training: 2 : 93.8 : Loss :0.347244\n",
      "Test: avg loss: 0.211346 accuracy 9354/10000 percentage 93.5\n",
      "Training: 2 : 95.9 : Loss :0.574818\n",
      "Test: avg loss: 0.205107 accuracy 9391/10000 percentage 93.9\n",
      "The current min 0.208682 new min 0.205107 saving...\n",
      "Training: 2 : 98.1 : Loss :0.366685\n",
      "Test: avg loss: 0.201569 accuracy 9410/10000 percentage 94.1\n",
      "The current min 0.205107 new min 0.201569 saving...\n",
      "Training: 3 : 0.0 : Loss :0.568506\n",
      "Test: avg loss: 0.204381 accuracy 9398/10000 percentage 94.0\n",
      "Training: 3 : 2.1 : Loss :0.420649\n",
      "Test: avg loss: 0.199268 accuracy 9433/10000 percentage 94.3\n",
      "The current min 0.204381 new min 0.199268 saving...\n",
      "Training: 3 : 4.3 : Loss :0.530597\n",
      "Test: avg loss: 0.201576 accuracy 9387/10000 percentage 93.9\n",
      "Training: 3 : 6.4 : Loss :0.474363\n",
      "Test: avg loss: 0.196761 accuracy 9404/10000 percentage 94.0\n",
      "The current min 0.199268 new min 0.196761 saving...\n",
      "Training: 3 : 8.5 : Loss :0.365473\n",
      "Test: avg loss: 0.197415 accuracy 9388/10000 percentage 93.9\n",
      "Training: 3 : 10.7 : Loss :0.382219\n",
      "Test: avg loss: 0.198480 accuracy 9410/10000 percentage 94.1\n",
      "Training: 3 : 12.8 : Loss :0.363700\n",
      "Test: avg loss: 0.196119 accuracy 9413/10000 percentage 94.1\n",
      "The current min 0.196761 new min 0.196119 saving...\n",
      "Training: 3 : 14.9 : Loss :0.543357\n",
      "Test: avg loss: 0.192760 accuracy 9411/10000 percentage 94.1\n",
      "The current min 0.196119 new min 0.192760 saving...\n",
      "Training: 3 : 17.1 : Loss :0.509572\n",
      "Test: avg loss: 0.187736 accuracy 9437/10000 percentage 94.4\n",
      "The current min 0.192760 new min 0.187736 saving...\n",
      "Training: 3 : 19.2 : Loss :0.303185\n",
      "Test: avg loss: 0.194195 accuracy 9409/10000 percentage 94.1\n",
      "Training: 3 : 21.3 : Loss :0.446084\n",
      "Test: avg loss: 0.196542 accuracy 9391/10000 percentage 93.9\n",
      "Training: 3 : 23.5 : Loss :0.371288\n",
      "Test: avg loss: 0.193266 accuracy 9421/10000 percentage 94.2\n",
      "Training: 3 : 25.6 : Loss :0.494176\n",
      "Test: avg loss: 0.188592 accuracy 9421/10000 percentage 94.2\n",
      "Training: 3 : 27.7 : Loss :0.657167\n",
      "Test: avg loss: 0.188783 accuracy 9420/10000 percentage 94.2\n",
      "Training: 3 : 29.9 : Loss :0.479395\n",
      "Test: avg loss: 0.186458 accuracy 9422/10000 percentage 94.2\n",
      "The current min 0.187736 new min 0.186458 saving...\n",
      "Training: 3 : 32.0 : Loss :0.452403\n",
      "Test: avg loss: 0.182911 accuracy 9442/10000 percentage 94.4\n",
      "The current min 0.186458 new min 0.182911 saving...\n",
      "Training: 3 : 34.1 : Loss :0.455569\n",
      "Test: avg loss: 0.185776 accuracy 9428/10000 percentage 94.3\n",
      "Training: 3 : 36.2 : Loss :0.516797\n",
      "Test: avg loss: 0.183699 accuracy 9443/10000 percentage 94.4\n",
      "Training: 3 : 38.4 : Loss :0.368722\n",
      "Test: avg loss: 0.183406 accuracy 9437/10000 percentage 94.4\n",
      "Training: 3 : 40.5 : Loss :0.383205\n",
      "Test: avg loss: 0.181030 accuracy 9456/10000 percentage 94.6\n",
      "The current min 0.182911 new min 0.181030 saving...\n",
      "Training: 3 : 42.6 : Loss :0.286043\n",
      "Test: avg loss: 0.176397 accuracy 9472/10000 percentage 94.7\n",
      "The current min 0.181030 new min 0.176397 saving...\n",
      "Training: 3 : 44.8 : Loss :0.326318\n",
      "Test: avg loss: 0.178046 accuracy 9437/10000 percentage 94.4\n",
      "Training: 3 : 46.9 : Loss :0.455395\n",
      "Test: avg loss: 0.174439 accuracy 9488/10000 percentage 94.9\n",
      "The current min 0.176397 new min 0.174439 saving...\n",
      "Training: 3 : 49.0 : Loss :0.430687\n",
      "Test: avg loss: 0.174742 accuracy 9492/10000 percentage 94.9\n",
      "Training: 3 : 51.2 : Loss :0.407123\n",
      "Test: avg loss: 0.171939 accuracy 9491/10000 percentage 94.9\n",
      "The current min 0.174439 new min 0.171939 saving...\n",
      "Training: 3 : 53.3 : Loss :0.437494\n",
      "Test: avg loss: 0.171206 accuracy 9482/10000 percentage 94.8\n",
      "The current min 0.171939 new min 0.171206 saving...\n",
      "Training: 3 : 55.4 : Loss :0.343247\n",
      "Test: avg loss: 0.170295 accuracy 9484/10000 percentage 94.8\n",
      "The current min 0.171206 new min 0.170295 saving...\n",
      "Training: 3 : 57.6 : Loss :0.408147\n",
      "Test: avg loss: 0.173732 accuracy 9474/10000 percentage 94.7\n",
      "Training: 3 : 59.7 : Loss :0.476655\n",
      "Test: avg loss: 0.175027 accuracy 9487/10000 percentage 94.9\n",
      "Training: 3 : 61.8 : Loss :0.331671\n",
      "Test: avg loss: 0.167319 accuracy 9507/10000 percentage 95.1\n",
      "The current min 0.170295 new min 0.167319 saving...\n",
      "Training: 3 : 64.0 : Loss :0.327096\n",
      "Test: avg loss: 0.170232 accuracy 9498/10000 percentage 95.0\n",
      "Training: 3 : 66.1 : Loss :0.417539\n",
      "Test: avg loss: 0.168394 accuracy 9485/10000 percentage 94.8\n",
      "Training: 3 : 68.2 : Loss :0.319674\n",
      "Test: avg loss: 0.163391 accuracy 9497/10000 percentage 95.0\n",
      "The current min 0.167319 new min 0.163391 saving...\n",
      "Training: 3 : 70.4 : Loss :0.613189\n",
      "Test: avg loss: 0.167086 accuracy 9478/10000 percentage 94.8\n",
      "Training: 3 : 72.5 : Loss :0.434041\n",
      "Test: avg loss: 0.163111 accuracy 9502/10000 percentage 95.0\n",
      "The current min 0.163391 new min 0.163111 saving...\n",
      "Training: 3 : 74.6 : Loss :0.325894\n",
      "Test: avg loss: 0.162316 accuracy 9503/10000 percentage 95.0\n",
      "The current min 0.163111 new min 0.162316 saving...\n",
      "Training: 3 : 76.8 : Loss :0.463324\n",
      "Test: avg loss: 0.165664 accuracy 9492/10000 percentage 94.9\n",
      "Training: 3 : 78.9 : Loss :0.342905\n",
      "Test: avg loss: 0.161495 accuracy 9500/10000 percentage 95.0\n",
      "The current min 0.162316 new min 0.161495 saving...\n",
      "Training: 3 : 81.0 : Loss :0.331616\n",
      "Test: avg loss: 0.163782 accuracy 9504/10000 percentage 95.0\n",
      "Training: 3 : 83.2 : Loss :0.381077\n",
      "Test: avg loss: 0.164408 accuracy 9492/10000 percentage 94.9\n",
      "Training: 3 : 85.3 : Loss :0.458389\n",
      "Test: avg loss: 0.162732 accuracy 9510/10000 percentage 95.1\n",
      "Training: 3 : 87.4 : Loss :0.448353\n",
      "Test: avg loss: 0.158573 accuracy 9523/10000 percentage 95.2\n",
      "The current min 0.161495 new min 0.158573 saving...\n",
      "Training: 3 : 89.6 : Loss :0.390199\n",
      "Test: avg loss: 0.157130 accuracy 9529/10000 percentage 95.3\n",
      "The current min 0.158573 new min 0.157130 saving...\n",
      "Training: 3 : 91.7 : Loss :0.288062\n",
      "Test: avg loss: 0.153764 accuracy 9523/10000 percentage 95.2\n",
      "The current min 0.157130 new min 0.153764 saving...\n",
      "Training: 3 : 93.8 : Loss :0.386061\n",
      "Test: avg loss: 0.154686 accuracy 9522/10000 percentage 95.2\n",
      "Training: 3 : 95.9 : Loss :0.376995\n",
      "Test: avg loss: 0.155029 accuracy 9525/10000 percentage 95.2\n",
      "Training: 3 : 98.1 : Loss :0.378426\n",
      "Test: avg loss: 0.153797 accuracy 9520/10000 percentage 95.2\n"
     ]
    }
   ],
   "source": [
    "test(network=network,test_loader=test_loader)\n",
    "for e in range(1, epochs+1):\n",
    "    train(epoch=e,interval=log_interval,network=network,optimizer=optimizer, data_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: avg loss: 0.153764 accuracy 9523/10000 percentage 95.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1537640869140625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.load_state_dict(torch.load(\"./result/model.pth\"))\n",
    "test(network=network,test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('newDL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2d0bf7df40b2194de3bc3581e962168d8bda644dc8a5bca8e73878a3301f531"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
